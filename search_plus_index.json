{"./":{"url":"./","title":"关于博客说明","keywords":"","body":"博客简介： 博客是博主多年的测试和运维工作的知识总结，主要涉及测试、运维以及docker容器编排和部署等方面知识，也会涉及到cicd、Linux方面知识；甚至有多种工具和shell语言组合后的东西；博主希望通过对自己掌握的知识进行汇总，展示出来，给需要的人提供帮助或者思路。若能帮助到大家，也就达到博主的目的。 如果大家是用手机浏览 本网站，下拉滑动后点击左上角，即可看到目录树，来查看所需的文章。 本人csdn博客地址：https://blog.csdn.net/qq_39919755 会不定期进行同步，毕竟csdn被百度抓取可能性较大，能帮助到更多利用搜索器寻找答案的人； 博客主要分为Linux、shell、Jenkins、docker、kubernetes（rancher）、NGINX、git、jmeter、自动化测试、大数据处理等几大类，绝大部分都是原创，甚至很多是博主亲身踩过的坑，借博客形式展示出来，在运维和测试人员遇到类似问题、场景提供解决思路或者灵感 若要转载博客，请注明出处；若商用，请联系博主 博主目前处于待业期，如果北京朝阳区这边 有运维、自动化测试相关工作 ，可以给博主发邮件631782068@qq.com "},"linux/tar-deal.html":{"url":"linux/tar-deal.html","title":"\"-\"在tar命令中的巧用","keywords":"","body":"\"-\"在tar命令中的巧用 首先来看示例： tar -cvf - /home | tar -xvf - 前面把压缩结果存到-，后面通过管道 | 把存到-中的文件解压，如果纯粹看这个，觉得这不瞎折腾么，下面从实战来说明使用它的好处 实战案例1： 海量小文件传输方法 接收机：nc -l 8888 | tar xzf - -C /dest-dir 发送机：tar czf - /source-dir/ | nc 接收机ip 8888 在 GNU 指令中，如果单独使用 - 符号，不加任何该加的文件名称时，代表\"标准输入/输出\"的意思,上面命令把结果输入到-,然后再解压-; 接收机可以带上参数v,如 xzvf（便于可视化）；如果发送机压缩命令带有z接收机也必须带上参数z 另外8888或其他端口，一定要放开，或者关闭防火墙；通过这种方式传递文件，相等于把先把文件压缩、然后通过scp 传输、再解压这几步合并成两步，并且省去了等待压缩和解压的时间。 实战案例2： find /directory -type f -name \"mypattern\" | tar -cf archive.tar -T - 找到匹配的文件后，直接压缩 实战案例3 docker cp 命令 docker cp命令中用法 ]# docker cp --help Usage: docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|- ​ docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH 官网解释： Use ‘-‘ as the source to read a tar archive from stdin and extract it to a directory destination in a container. Use ‘-‘ as the destination to stream a tar archive of a container source to stdout. 所以我们可以 docker cp cfcc20077ad1:/opt/aa.tgz - | tar xvf - -C ./xx tar czf - anaconda-ks.cfg initial-setup-ks.cfg | docker cp - cfcc20077ad1:/opt/mydir tar成对使用，前面一个是stdin 后面一个是stdout , 最终文件不会改变，-里面存的是压缩包，传输完成后还是压缩包，如果是文件传输完成后还是文件 ，只不过tar 传输比较快 "},"linux/limit_ip.html":{"url":"linux/limit_ip.html","title":"利用iptables或防火墙指定ip访问服务器某个端口","keywords":"","body":"如何利用iptables或防火墙指定ip访问服务器某个端口 有如下两种方式： 1 firewall-cmd --permanent --add-rich-rule 'rule family=ipv4 source address=10.219.82.83 port port=12181 protocol=tcp accept' systemctl restart firewalld 移除--add-rich-rule规则 用--remove-rich-rule= 帮助文档显示： --list-rich-rules List rich language rules added for a zone [P] [Z] --add-rich-rule= ​ Add rich language rule 'rule' for a zone [P] [Z] [T] --remove-rich-rule= ​ Remove rich language rule 'rule' from a zone [P] [Z] 2 iptables-save > iptables.rules /sbin/iptables -A INPUT -s 172.16.35.31 -p tcp --dport 12181 -j ACCEPT # 中控白名单 /sbin/iptables -A OUTPUT -d 172.16.35.31 -p tcp --sport 12181 -j ACCEPT /sbin/iptables -A INPUT -p tcp --dport 12181 -j DROP #其他服务器无法访问12181端口 /sbin/iptables -A OUTPUT -p tcp --sport 12181 -j DROP \\#iptables --list-rules #查看规则 ，根据情况删除下面规则 \\#iptables -D INPUT -j REJECT --reject-with icmp-host-prohibited # \\#iptables -D FORWARD -j REJECT --reject-with icmp-host-prohibited # service iptables save systemctl restart iptables "},"linux/set_ip.html":{"url":"linux/set_ip.html","title":"如何设置centos7.6和Ubuntu19.4的ip4","keywords":"","body":"centos7.6和Ubuntu19.04设置ip centos7任何版本都可以通过nmtui命令来设置ip， 但centos7.6ip的设置需要注意，在网卡配置文件/etc/sysconfig/network-scripts/ifcfg-eth0 ,需要配置如下两项 #网卡eth0名称因环境而已 ONBOOT=yes IPV6_PRIVACY=no 一定要增加 IPV6_PRIVACY=no ，centos7.6 默认采用IP6技术了 Ubuntu19.4 配置静态IP sudo vim /etc/netplan/50-cloud-init.yaml #文件名称因环境而异，但一定是*.yaml network: ​ ethernets: ​ ens33: ​ dhcp4: no ​ addresses: [192.16.1.101/24, ] ​ gateway4: 192.16.1.2 ​ nameservers: ​ addresses: [192.16.1.2,8.8.8.8] ​ version: 2 完成后执行 sudo netplan apply 即可生效,博主参考了：https://www.tecmint.com/configure-network-static-ip-address-in-ubuntu/ "},"linux/extend_disk.html":{"url":"linux/extend_disk.html","title":"Linux中磁盘扩展与缩减","keywords":"","body":"磁盘扩展和缩减知识汇总 新增分区，挂靠到新的目录方法 1,首先通过命令lsblk 查看增加分区的情况； [root@apptrace0011 ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 501G 0 disk ├─sda1 8:1 0 1G 0 part /boot ├─sda2 8:2 0 199G 0 part │ ├─centos-root 253:0 0 50G 0 lvm / │ ├─centos-swap 253:1 0 3.9G 0 lvm [SWAP] │ └─centos-home 253:2 0 445.1G 0 lvm /home └─sda3 8:3 0 301G 0 part └─centos-home 253:2 0 445.1G 0 lvm /home sdb 8:16 0 10G 0 disk sr0 11:0 1 1024M 0 rom 关于sda/sdb说明，如果通过vmmare 虚拟机控制台等工具，直接在原有的1个硬盘扩充的存储空间；如原有硬盘是200G， 扩充到500G扩充后，扩充的存储还是在sda分区下；如果新增一个硬盘，是在sdb分区，依次类推sdc…… 关于sda/sdb说明，如果通过vmmare 虚拟机控制台等工具，直接在原有的1个硬盘扩充的存储空间；如原有硬盘是200G， 扩充到500G扩充后，扩充的存储还是在sda分区下；如果新增一个硬盘，是在sdb分区，依次类推sdc…… 2，通过命令fdisk -l [root@apptrace0011 ~]# fdisk -l Disk /dev/sda: 537.9 GB, 537944653824 bytes, 1050673152 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000e999c Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 1 FAT12 /dev/sda2 2099200 419430399 208665600 8e Linux LVM /dev/sda3 419430400 1050673151 315621376 8e Linux LVM Disk /dev/sdb: 10.7 GB, 10737418240 bytes, 20971520 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-root: 53.7 GB, 53687091200 bytes, 104857600 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-swap: 4160 MB, 4160749568 bytes, 8126464 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-home: 477.9 GB, 477940940800 bytes, 933478400 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 查看到sda 硬盘和sdb硬盘的情况，sda都已经做分区（但还有空间可以进行分区，下种类型讲） sdb还未有分区；如果新增了硬盘，没有看到可以执行命令： partprobe /dev/sdb ,没有这个命令，自行安装 yum -y install parted 查看到sda 硬盘和sdb硬盘的情况，sda都已经做分区（但还有空间可以进行分区，下种类型讲） sdb还未有分区；如果新增了硬盘，没有看到可以执行命令： partprobe /dev/sdb ,没有这个命令，自行安装 yum -y install parted 3，如果新增硬盘在sdb下 可以按照如下方式直接挂载 fdisk /dev/sdb 输入m 查看用法 最常用几个用法 p 打印分区情况 n 新增分区； d删除分区；w保存 t改变格式 输入p 打印分区情况 输入 n新增分区 Partition number (1-4, default 1): 正常情况默认选中1；，如果上步p打印时已经有sdb1，输入2 然后输入t 改变分区格式 Command (m for help): t Selected partition 1 Partition type (type L to list all types): L 0 Empty 24 NEC DOS 81 Minix / old Lin bf Solaris 1 FAT12 27 Hidden NTFS Win 82 Linux swap / So c1 DRDOS/sec (FAT- 2 XENIX root 39 Plan 9 83 Linux c4 DRDOS/sec (FAT- 3 XENIX usr 3c PartitionMagic 84 OS/2 hidden or c6 DRDOS/sec (FAT- 4 FAT16 选择8e Linux LVM 这个格式，(有的是83、linux格式的) 最后输入w 保存退出（不能漏掉） Partition type (type L to list all types): 8e Changed type of partition 'Linux' to 'Linux LVM'. 如果保存出现错误,可以 partprobe /dev/sdb (没有数字） 然后再进入 fdisk /dev/sdb 继续上面的操作 甚至重启 如果保存出现错误,可以 partprobe /dev/sdb (没有数字） 然后再进入 fdisk /dev/sdb 继续上面的操作 甚至重启 4，接着格式化： centos7 可以用mkfs.xfs /dev/sdb1 ，Ubuntu或者centos6 用mkfs.ext4 /dev/sdb1 来格式 输入mkfs. 按tab键，可以看出有哪些格式 [root@apptrace0011 ~]# mkfs. mkfs.btrfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.minix mkfs.xfs 5，进行挂载： mount /dev/sdb1 /data/（新目录或者老目录，如果没有需求提前创建） 6，开机生效，编辑 /etc/fstab /dev/mapper/centos-root / xfs defaults 0 0 UUID=3c94bedd-2b80-47d3-a3a4-05785847aa10 /boot xfs defaults 0 0 /dev/mapper/centos-home /home xfs defaults 0 0 /dev/mapper/centos-swap swap swap defaults 0 0 把刚才的/data 添加进去 /dev/sdb1 /data xfs defaults 0 0 或者 UUID=3c94bedd-2b80-47d3-a3a4-05785847aa10 /data xfs defaults 0 0 如果是在物理机上，增加硬盘后，最好填写uuid，分区是可以变化，uuid不会变； 如果是在物理机上，增加硬盘后，最好填写uuid，分区是可以变化，uuid不会变； 9.其他命令 blkid查看挂载硬盘的UUID，如blkid | grep \"sdb*\" ，查看现有分区cat /proc/partitions 把刚才的/data 添加进去 /dev/sdb1 /data xfs defaults 0 0 或者 UUID=3c94bedd-2b80-47d3-a3a4-05785847aa10 /data xfs defaults 0 0 如果是在物理机上，增加硬盘后，最好填写uuid，分区是可以变化，uuid不会变； 8.其他命令 blkid查看挂载硬盘的UUID，如blkid | grep \"sdb*\"，查看现有分区cat /proc/partitions 如果是在物理机上，增加硬盘后，最好填写uuid，分区是可以变化，uuid不会变； 7.其他命令 blkid查看挂载硬盘的UUID，如blkid | grep \"sdb*\"，查看现有分区cat /proc/partitions 怎么把原有硬盘扩充的存储都挂靠到/home（或其他已有目录） 1，查看新增硬盘情况，如下，原有硬盘从200G增加到300G [root@part-add ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 300G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 199G 0 part ├─centos-root 253:0 0 50G 0 lvm / ├─centos-swap 253:1 0 3.9G 0 lvm [SWAP] └─centos-home 253:2 0 145.1G 0 lvm /home sr0 11:0 1 1024M 0 rom 再查看fdisk情况 [root@part-add ~]# fdisk -l Disk /dev/sda: 322.1 GB, 322122547200 bytes, 629145600 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000e999c Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 419430399 208665600 8e Linux LVM Disk /dev/mapper/centos-root: 53.7 GB, 53687091200 bytes, 104857600 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-swap: 4160 MB, 4160749568 bytes, 8126464 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-home: 155.8 GB, 155818393600 bytes, 304332800 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 2，把增加的硬盘容量全部分到一个新分区sda3上 fdisk /dev/sda Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): p Disk /dev/sda: 322.1 GB, 322122547200 bytes, 629145600 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000e999c Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 419430399 208665600 8e Linux LVM Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): First sector (419430400-629145599, default 419430400): Using default value 419430400 Last sector, +sectors or +size{K,M,G} (419430400-629145599, default 629145599): Using default value 629145599 Partition 3 of type Linux and of size 100 GiB is set Command (m for help): p Disk /dev/sda: 322.1 GB, 322122547200 bytes, 629145600 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000e999c Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 419430399 208665600 8e Linux LVM /dev/sda3 419430400 629145599 104857600 83 Linux Command (m for help): t Partition number (1-3, default 3): Hex code (type L to list all codes): 8e （注意lvm格式） Changed type of partition 'Linux' to 'Linux LVM' Command (m for help): p Disk /dev/sda: 322.1 GB, 322122547200 bytes, 629145600 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000e999c Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 419430399 208665600 8e Linux LVM /dev/sda3 419430400 629145599 104857600 8e Linux LVM Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. WARNING: Re-reading the partition table failed with error 16: Device or resource busy. The kernel still uses the old table. The new table will be used at the next reboot or after you run partprobe(8) or kpartx(8) Syncing disks. [root@part-add ~]# partprobe /dev/sda [root@part-add ~]# partprobe /dev/sda3 [root@part-add ~]# fdisk -l Disk /dev/sda: 322.1 GB, 322122547200 bytes, 629145600 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000e999c Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 419430399 208665600 8e Linux LVM /dev/sda3 419430400 629145599 104857600 8e Linux LVM Disk /dev/mapper/centos-root: 53.7 GB, 53687091200 bytes, 104857600 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-swap: 4160 MB, 4160749568 bytes, 8126464 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-home: 155.8 GB, 155818393600 bytes, 304332800 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 3，新增分区格式化（执行顺序可以和下面第4部互换） mkfs.xfs /dev/sda3 meta-data=/dev/sda3 isize=512 agcount=4, agsize=6553600 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=26214400, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=12800, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 4，增加物理卷： pvcreate 刚才创建的分区 [root@part-add ~]# pvcreate /dev/sda3 WARNING: xfs signature detected on /dev/sda3 at offset 0. Wipe it? [y/n]: y Wiping xfs signature on /dev/sda3. Physical volume \"/dev/sda3\" successfully created. 查看物理卷增加后的情况 [root@part-add ~]# pvdisplay 或者pvs --- Physical volume --- PV Name /dev/sda2 VG Name centos PV Size 5，将物理卷加入到卷组 1）先看卷组信息 [root@part-add ~]# vgdisplay 或者vgs --- Volume group --- VG Name centos System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 3 Open LV 2 Max PV 0 Cur PV 1 Act PV 1 VG Size 2）把新的分区加入到卷组 vgextend centos（VG Name） /dev/sda3 （新分区） [root@part-add ~]# vgextend centos /dev/sda3 Volume group \"centos\" successfully extended - 3）再次查看 验证 [root@part-add ~]# vgdisplay --- Volume group --- VG Name centos System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 5 VG Access read/write VG Status resizable MAX LV 0 Cur LV 3 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size 298.99 GiB PE Size 4.00 MiB Total PE 76542 Alloc PE / Size 50942 / 198.99 GiB Free PE / Size 25600 / 100.00 GiB VG UUID iza5sY-YoTh-ihTR-dLzZ-2CBx-M0dR-33bzW5 此时VG Size 大小已有 298.99 GiB 6，扩充逻辑卷 1）先通过下面命令查看系统里有哪些逻辑卷。 ``` [root@part-add ~]# lvdisplay 或者lvs --- Logical volume --- LV Path /dev/centos/swap LV Name swap VG Name centos LV UUID m8Dc95-LYbI-cxuG-hNc7-COoH-4Axh-7mamwX LV Write Access read/write LV Creation host, time localhost, 2018-08-31 18:38:32 +0800 LV Status available LV Size currently set to 8192 Block device 253:1 --- Logical volume --- LV Path /dev/centos/home LV Name home VG Name centos LV UUID 1HItab-O0cU-CEkB-cplf-6axH-utqI-Fgxi5n LV Write Access read/write LV Creation host, time localhost, 2018-08-31 18:38:33 +0800 LV Status available LV Size 有/dev/centos/swap /dev/centos/home /dev/centos/root这三个逻辑卷, 其中逻辑卷/dev/centos/home （挂载点是home目录下）就是本次要扩充的对象（同理根目录/ 对应的 /dev/centos/root也可以安装此方法) 2)扩充逻辑卷/dev/centos/home lvextend -L +100G /dev/mapper/centos-home 或者：lvextend -l 提示数量（可以查看Current LE，如果提示太多，减少到提示的最多数量） /dev/mapper/centos-home lvextend -l +100%FREE /dev/mapper/centos-home [root@part-add ~]# lvextend -L +100G /dev/mapper/centos-home Size of logical volume centos/home changed from 3）扩充到文件系统（目录）中，xfs_growfs /dev/centos/home 如果是ext格式 则用resize2fs /dev/centos/home [root@part-add ~]# xfs_growfs /dev/centos/home meta-data=/dev/mapper/centos-home isize=512 agcount=4, agsize=9510400 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=38041600, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=18575, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 38041600 to 64256000 [root@part-add ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 50G 1.5G 49G 3% / devtmpfs 1.9G 0 1.9G 0% /dev tmpfs 1.9G 0 1.9G 0% /dev/shm tmpfs 1.9G 8.9M 1.9G 1% /run tmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup /dev/sda1 1014M 184M 831M 19% /boot tmpfs 380M 0 380M 0% /run/user/0 /dev/mapper/centos-home 246G 33M 246G 1% /home 重启后再查看 df -h ，是扩充成功后的；一般不需重启。但最好mount -a 生效一下 新增磁盘挂载步骤概述 如何给服务器增加三块硬盘 ： 1，将三块硬盘增加到pv（物理卷） pvcreate /dev/sdb /dev/sdc /dev/sdd 2,将pv加入到vg（卷）组 vgcreate datavg /dev/sdb /dev/sdc /dev/sdd 3,分配逻辑卷 lvcreate -l 50%FREE -n lv1 datavg lvcreate -L +200M -n lv2 datavg 4,格式化逻辑卷 mkfs.xfs /dev/datavg/lv1 mkfs.ext4 /dev/datavg/lv2 5,挂载 mkdir /lv1 /lv2 mount /dev/datavg/lv1 /lv1 mount /dev/datavg/lv2 /lv2 扩展磁盘步骤概述 1，添加物理磁盘 ​ pvcreate /dev/sdd 2，扩展到现有vg组 ​ vgextend 现有卷组名称 /dev/sdd 3，扩充到现有逻辑卷中 ​ lvextend -L +100G /dev/mapper/centos-home lvextend -l +100%FREE(或者扩展数量) /dev/mapper/centos-home 4，扩充到文件系统中 ​ xfs_growfs /dev/centos/home resize2fs /dev/centos/home ​ vg组减小和迁移等步骤概述 1，减小vg ​ vgremove vg组名 /dev/sdd (或者其他要移动物理卷) 2，迁移vg ​ 迁移vg里面的物理卷，必须是在同一个vg组中 ​ vgmove /dev/sdb /dev/sdc (在线迁移) "},"linux/use_heredoc.html":{"url":"linux/use_heredoc.html","title":"heredocument的巧用","keywords":"","body":"heredocument 的巧用 我们经常使用 cat >(或>>) xxx来把内容添加某个文件中，这就是heredocument 的一种用法，但heredocument 用法不仅仅限制于此 情景1： 我们需要先登录mysql后 才能执行sql脚本 这个时候 就可以利用heredocument mysql -uroot -pxxxx 情景2： :执行某个脚本实现登录后，然后执行相关操作 可以借鉴here document ，写成脚本 #!/bin/bash ./xxx.sh xxx.sh 也可以是可执行的二进制文件 注意： 另外eof包含的内容，含有变量的话 ，不被替换 可以写作 ./xxxx.sh eof块的内容会原封不动的保存 "},"docker/docker-install.html":{"url":"docker/docker-install.html","title":"docker 安装与优化","keywords":"","body":"Docker CE for CentOS 7.5/ubuntu19.04(centos7.5或以上版本) centos安装docker 安装yum⼯具 sudo yum install -y yum-utils 配置docker yum源 sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum makecache fast 查询可⽤版本 sudo yum list docker-ce --showduplicates | sort -r 安装指定版本docker-ce-17.03.2.ce,要先安装docker-ce-selinux-17.03.2.ce，否则安装docker-ce会报错 1 sudo yum -y install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.2.ce-1.el7.centos.noarch.rpm 2 sudo yum -y install docker-ce-17.03.2.ce-1.el7.centos 如果只下载安装包（和依赖库）： yum install -y docker-ce-17.03.2.ce --downloadonly --downloaddir=./ 安装最新版的docker sudo yum -y install docker-ce centos（Redhat）离线安装 只需要下载对应版本RPM包 即可； 阿里镜像源地址 如安装docker-18.09.5，下载对应的3个RPM包即可 containerd.io-1.2.5-3.1.el7.x86_64.rpm docker-ce-18.09.5-3.el7.x86_64.rpm docker-ce-cli-18.09.5-3.el7.x86_64.rpm 利用rancher提供的安装脚本在线安装docker 1，首先下载安装脚本 curl -OS https://releases.rancher.com/install-docker/18.09.sh 2，如果有连接外网VPN，可以使用 curl https://releases.rancher.com/install-docker/18.09.sh |sudo sh直接安装，但这个不建议 如果直接在线执行，缺点是无法修改脚本,失败率高，不建议,因为在centos安装时失败，并提示yum 源找不到可以通过修改一行代码，改用阿里的镜像源 centos|fedora|redhat|oraclelinux) #yum_repo=\"https://download.docker.com/linux/centos/docker-ce.repo\" yum_repo=\"https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\" 3, 下载脚本后第一件事就是修改为阿里的镜像源 下载脚本 阿里镜像源地址：https://mirrors.aliyun.com/docker-ce/linux/ 所以把 https://download.docker.com/linux 全部替换为： https://mirrors.aliyun.com/docker-ce/linux vi 或者vim 18.09.sh :%s/https:\\/\\/download.docker.com\\/linux/https:\\/\\/mirrors.aliyun.com\\/docker-ce\\/linux/g 然后执行sh 18.09.sh 安装成功的 Ubuntu安装docker Ubuntu执行rancher提供docker安装脚本 执行时报错： + sh -c apt-get install -y -q docker-ce= Reading package lists... Building dependency tree... Reading state information... E: Version '' for 'docker-ce' was not found 这个可能Ubuntu版本太高，需要手动来安装docker了 可以把下面命令执行完成后，再来执行rancher提供的docker安装脚本 sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common bash-completion # step 2: 安装GPG证书 sudo curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - # Step 3: 写入软件源信息 sudo add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" # Step 4: 更新并安装 Docker-CE sudo apt-get -y update ubuntu在线安装 sudo apt install docker.io 或sudo apt install docker-ce ubuntu离线安装 暂缺 rancher提供的docker安装脚本的GitHub：https://github.com/rancher/install-docker 改变docker的image存放⽬录（下面提供三种方式）、配置加速器等 修改配置文件，配置加速器 中写入如下内容（如果文件不存在请新建该文件） [root@yktapp1 dockersh]# cat /etc/docker/daemon.json { \"registry-mirrors\": [ \"https://registry.docker-cn.com\" ] } 也可以使用阿里的镜像加速器和本地仓库配置 #### 使用内部仓库地址的配置 [root@yktapp1 dockersh]# cat /etc/docker/daemon.json { \"registry-mirrors\": [\"https://registry.docker-cn.com\"], \"insecure-registries\": [\"0.0.0.0/0\"] } \"insecure-registries\": [\"0.0.0.0/0\"] 通配表示所有http协议仓库，如果只想通配某个http协议仓库，可以写成具体名称或者通配 \"insecure-registries\":[\"10.251.66.44:5000\"] \"insecure-registries\":[\"10.251.26.0/24\"] - 参考harbor GitHub文档说明 If this private registry supports only HTTP or HTTPS with an unknown CA certificate, please add --insecure-registry myregistrydomain.com to the daemon's start up arguments. In the case of HTTPS, if you have access to the registry's CA certificate, simply place the CA certificate at /etc/docker/certs.d/myregistrydomain.com/ca.crt . 自签名https和不安全http都可以用这种方式解决，自签名的证书，也可以把证书copy到相应目录解决，无需添加insecure-registries选项，具体方法参见harbor的使用说明 - 注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。 ##### 1），指定docker存储位置，方法1（指定了overlay2，这种方式比overlay更高效，kernel较高的Linux默认就是这种） cat > /etc/docker/daemon.json https://wgaccbzr.mirror.aliyuncs.com\"], \"data-root\": \"/app/lib/docker\" } { \"storage-driver\": \"overlay2\", \"storage-opts\":[\"overlay2.override_kernel_check=true\"] } EOF #### 2），把指定的盘符挂载给docker 直接修改/etc/fstab中把一个逻辑卷挂到docker存储目录 /var/lib/docker中，但要确保原有的挂载没有东西，并取消之前的挂载关系， umout -a oldpath；可以通过下面查看原有的挂载和逻辑卷情况 [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT fd0 2:0 1 4K 0 disk sda 8:0 0 100G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 99G 0 part ├─centos-root 253:0 0 50G 0 lvm / ├─centos-swap 253:1 0 7.9G 0 lvm [SWAP] └─centos-home 253:2 0 41.1G 0 lvm /home #### 3），软链的方式 （不推荐，作为挽救使用） systemctl stop docker mv /var/lib/docker /home/docker ln -s /home/docker /var/lib/docker systemctl start docker ### 安装 docker-compose wget -c https://github.com/docker/compose/releases/download/1.22.0/docker-compose-`uname -s-uname -m` cp docker-compose-Linux-x86_64 /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose - 之后重新启动服务。 sudo systemctl daemon-reload sudo systemctl start docker sudo systemctl enable docker - 注意最好配置完成好了 再启动docker，避免启动docker产生文件存储在默认的路径 ### 测试安装是否成功 docker ps ### 非root用户操作docker sudo gpasswd -a your-user docker or sudo usermod -aG docker your-user 这两种方式 都是把非root用户添加到docker组 ## Kernel性能调优 cat >> /etc/sysctl.conf "},"docker/harbor-install.html":{"url":"docker/harbor-install.html","title":"harbor的安装和注意事项","keywords":"","body":"安装harbor说明 官方说明文档：https://github.com/goharbor/harbor/blob/release-1.7.0/docs/installation_guide.md 选择在线还是离线根据情况，这里不作为操作重点； 离线安装包下载地址 https://github.com/goharbor/harbor/releases 如果采用https协议，并使用自签名的证书的话，可以使用https://github.com/xiaoluhong/server-chart/blob/v2.2.2/create_self-signed-cert.sh 脚本生成证书 在线安装http协议的harbor(默认使用此协议的，简单) 下载完成在线安装包解压后，在harbor目录，备份 docker-compose.yml后再修改 container_name: nginx restart: always cap_drop: - ALL cap_add: - CHOWN - SETGID - SETUID - NET_BIND_SERVICE volumes: - ./common/config/nginx:/etc/nginx:z networks: - harbor dns_search: . ports: - 1180:80 - 5555:443 - 34443:4443 由于宿主机的80和443端口已经被用掉，只能映射成其他端口；如果是一台新机器 无需这么操作 harbor.cfg备份后修改如下两个参数 hostname = 172.16.35.31:1180 ui_url_protocol = http 修改完成后执行 ./install.sh 然后就可以在浏览器中访问了：http://172.16.35.31:1180 在harbor/common目录有两个子目录，分别是：config templates 其中templates是原始文件，config是执行install.sh 或prepare 后生成的，所以尽量修改templates目录下的文件； 如果要修改harbor的配置，按照官方文档“Managing Harbor's lifecycle” 来操作 执行install.sh 相当于 ./prepare docker-compose up -d 这两步，所以修改完成后 要么执行install.sh 要么执行这两步； 如果出现误操作，可以通过docker-compose down -v 再重新执行 如何使用http协议登录和推送镜像 最新版本docker 默认不允许使用http推送，所以我们要修改 在harbor宿主机和远程推送镜像的机器都增加如下配置 vi /etc/docker/daemon.json{ \"insecure-registries\":[\"172.16.35.31:1180\"] } 或者直接在已有配置后面添加 { \"registry-mirrors\": [ \"https://registry.docker-cn.com\" ], \"insecure-registries\":[\"172.16.35.31:1180\"] } 也可以使用0.0.0.0通配所有的http镜像仓库 \"insecure-registries\": [\"0.0.0.0/0\"] 修改harbor宿主机docker启动项配置/usr/lib/systemd/system/docker.service 如果docker17.3版本，直接参照下面方式添加ExecStart=/usr/bin/dockerd --insecure-registry=172.16.35.31:1180 如果docker是最新18.9或者以上版本，直接参照下面方式添加ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock --insecure-registry=172.16.35.31:1180 完成后，重启dockersystemctl daemon-reload systemctl restart docker 验证参数：ps aux|grep dockerd root 106472 31.5 0.0 2150816 71576 ? Ssl 17:06 0:02 /usr/bin/dockerd -H unix:///var/run/docker.sock --insecure-registry=172.16.35.31:1180 远程或者本地登录验证 docker login 172.16.35.31:1180 Username: admin Password: Login Succeeded 若登录时提示net/http: request canceled (Client.Timeout exceeded while awaiting headers) 这是代理搞的鬼，把代理/etc/systemd/system/docker.service.d/http-proxy.conf或者其他配置，里面[Service] Environment=\"HTTP_PROXY=http://10.xx.xx.83:3128\" Environment=\"NO_PROXY=localhost,127.0.0.0/8,10.42.*.*\" 把登录时的ip 加入到NO_PROXY中，支持通配符 开放管理端口映射（http协议，可选操作） 管理端口在 /lib/systemd/system/docker.service 文件中 将其中第11行的 ExecStart=/usr/bin/dockerd 替换为： ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock -H tcp://0.0.0.0:7654 （此处默认2375为主管理端口，unix:///var/run/docker.sock用于本地管理，7654是备用的端口） 将管理地址写入 /etc/profile echo 'export DOCKER_HOST=tcp://0.0.0.0:2375' >> /etc/profile 管理接口以备Jenkins等工具调用使用。 离线安装https协议的harbor 生成证书 1，执行create_self-signed-cert.sh 带上相应参数生成所需自签名证书（可以-h,查看用法；如果有证书，忽略此步） cat /etc/hosts 192.16.1.100 Centos76 reg.czl.com 具体名称和设置的自签名域名一致 ./create_self-signed-cert.sh --ssl-domain=reg.czl.com --ssl-trusted-ip=192.16.1.100 把生成的两个证书 copy到 /data/cert/ 2，配置harbor vi harbor.cfg hostname = 域名 （不能填写IP，如果用IP的话，采用http协议方式安装harbor） #自签名申请的域名如reg.czl.com 但采用了域名后，使用域名制作的证书，最好就填写域名避免出现 docker login ip 提示：certificate signed by unknown authority，linux终端用域名登录，浏览器端可以用域名也可以用https://ip登录， #打tag和推送也必须用域名 ui_url_protocol = https ssl_cert = /data/cert/tls.crt ssl_cert_key = /data/cert/tls.key #ssl_cert = /data/cert/server.crt #ssl_cert_key = /data/cert/server.key 3，执行安装命令 ### 4,如下操作和http协议的一样 但要注意，如果证书是自签名的 ，在其他机器登录此https协议的镜像库，还需要把tls.crt 推送过去 ```bash 非仓库机器： mkdir -p /etc/docker/certs.d/reg.czl.com/ 仓库机器把crt文件推送过去 scp tls.crt root@ip:/etc/docker/certs.d/reg.czl.com/ca.crt 如果是Ubuntu系统，root密码是随机的，可以分两步推送， 先推送给Ubuntu的常用账号，常用账号copy到指定目录 ` 服务器断电重启后，发现连接不上harbor 如何优化 如果断电或者机器重启后，harbor不可用，十有八九就是容器没有自动起来，我们可以完善一下，这个组件自带的docker-compose.yml 文件 如下所示，在每个容器策略里面加上restart选项，设置为unless-stopped，新版1.7.5版本harbor 全部组件restart 选项都设为always ,但还是需要手动停止部分组件后，再全部启动 注意事项 最好把harbor服务器的hostname或者别名加入到从harbor拉取镜像其他主机hosts文件中 vim /etc/hosts ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 172.16.35.31 szly-manage 常见参数解释说明 docker配置文件/etc/docker/daemon.json 或者启动脚本中 ExecStart参数 {\"hosts\": [\"fd://\", \"tcp://0.0.0.0:2375\"]} fd：// 指自动进行unix socket它 和-H unix:///var/run/docker.sock 、-H unix:// 作用相同，只是不同docker版本，写法略有差异。高版本的docker都已经采用了 -H 这种形式参数 小贴士 直接登录界面后，新建项目，在项目里面点击推送镜像，可以弹出镜像推送方法 更详细配置和证书生成脚本可以参考rancher提供的文档 https://www.cnrancher.com/docs/rancher/v2.x/cn/installation/registry/single-node-installation/ "},"docker/dockerfile-rule.html":{"url":"docker/dockerfile-rule.html","title":"如何制作出合适的镜像","keywords":"","body":"如何制作最合适docker镜像 控制镜像大小 优先选取基于alpine的镜像 查看tomcat镜像：https://hub.docker.com/_/tomcat?tab=tags （docker hup 中搜索tomcat镜像） 如tomcat8.5的镜像8.5-jre11 204 MB Last update: 13 days ago 而基于alpine的tomcat镜像8.5-jre8-alpine 72 MB Last update: 10 days ago 一眼就能看出来基于alpine的镜像比默认镜像少了130多M 但alpine镜像里面缺少了很多东西，设置不支持bash命令，我们可以在制作镜像时，一一给安装上，安装完成后删除缓存文件，就是安装文件； 选取国内的镜像源 如清华大学、阿里云等 Dockerfile示例： FROM alpine:3.7 MAINTAINER chenzhenglin #更新Alpine的软件源为国内（清华大学）的站点，因为从默认官源拉取实在太慢了。。。 RUN echo \"https://mirror.tuna.tsinghua.edu.cn/alpine/v3.7/main/\" > /etc/apk/repositories # 注意alpine的版本号 可能有差异，链接地址源最好用浏览器打开查看验证一下； 或用latest代替 RUN apk update \\ && apk upgrade \\ && apk add --no-cache bash \\ bash-doc \\ bash-completion \\ && apk add net-tools vim \\ && rm -rf /var/cache/apk/* \\ …… apk add --no-cache不使用本地缓存安装包数据库，直接从远程获取安装包信息安装。这样我们就不必通过apk update获取安装包数据库了，&&合并命令 好处是，多条命令合并成一条命令，减少docker images的层 如果基于centos或Ubuntu的系统 最好也要把软件源换成国内的 FROM centos:7.6.1810 RUN mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.bak && \\ curl -s http://mirrors.aliyun.com/repo/Centos-7.repo -o /etc/yum.repos.d/CentOS-Base.repo && \\ curl -s http://mirrors.aliyun.com/repo/epel-7.repo -o /etc/yum.repos.d/epel-7.repo && \\ yum repolist && \\ 注意：Alpine 镜像中的 telnet 在 3.7 版本后被转移至 busybox-extras 包中，所以apk add telnet 会报错 如下，一个基于tomcat:8.5-alpine镜像的Dockerfile，并验证通过 FROM tomcat:8.5-alpine MAINTAINER chenzhenglin #更新Alpine的软件源为国内（清华大学）的站点，因为从默认官源拉取实在太慢了…… alpine版本要从dockerfile里面查找到 RUN echo \"https://mirror.tuna.tsinghua.edu.cn/alpine/latest-stable/main/\" > /etc/apk/repositories # 注意alpine的版本号 可能有差异 RUN apk update \\ && apk upgrade \\ && apk add --update --no-cache net-tools vim busybox-extras curl \\ && rm -rf /var/cache/apk/* 查看镜像的Dockerfile 在docker hub 里面找到所需镜像后，在description的tab页，选择需要的版本，点击，一般会自动跳转到其githup源码界面； 如：https://hub.docker.com/_/tomcat?tab=description 如下Dockerfile文件FROM openjdk:8-jre ENV CATALINA_HOME /usr/local/tomcat ENV PATH $CATALINA_HOME/bin:$PATH RUN mkdir -p \"$CATALINA_HOME\" WORKDIR $CATALINA_HOME ……此处也省略不必要代码 RUN apt-get update && apt-get install -y --no-install-recommends \\ libapr1 \\ ……此处也省略不必要代码 apt-get install -y --no-install-recommends wget ca-certificates; \\ ……此处也省略不必要代码 # sh removes env vars it doesn't support (ones with periods) # https://github.com/docker-library/tomcat/issues/77 find ./bin/ -name '*.sh' -exec sed -ri 's|^#!/bin/sh$|#!/usr/bin/env bash|' '{}' +; \\ \\ ……此处也省略不必要代码 CMD [\"catalina.sh\", \"run\"] 从这个Dockerfile文件可以看出，已经安装了wget等工具，并把默认的sh换成了bash； 如何判断tomcat里面采用哪一版本的alpine呢,激活镜像后，查看其系统版本信息 cat /etc/os-release 同样其他linux也可以采用此方法查看版本号： cat /etc/redhat|centos-release alpine系统添加软件的常用方法，参见链接： https://wiki.alpinelinux.org/wiki/Alpine_Linux_package_management 其他精简镜像的方法 https://mp.weixin.qq.com/s/LOXNMYtZbnYeDR2lBI56fw "},"docker/save_load_images.html":{"url":"docker/save_load_images.html","title":"逐个和批量导出导入docker镜像","keywords":"","body":"逐个导出镜像 #!/bin/bash IMAGES_LIST=($(docker images | sed '1d' | awk '{print $1}')) IMAGES_NM_LIST=($(docker images | sed '1d' | awk '{print $1\"-\"$2}'| awk -F/ '{print $NF}')) IMAGES_NUM=${#IMAGES_LIST[*]} for((i=0;i注意 这个慎用，如果一个镜像有多个版本，容易出现问题，采用下面的批量导入 批量导入到一个压缩包 #!/bin/bash IMAGES_LIST=($(docker images | sed '1d' | awk '{print $1\":\"$2}')) docker save ${IMAGES_LIST[*]} -o all-images.tar.gz 把一个压缩包所有镜像导出并上传到仓库 ./rancher-load-images.sh -l rancher-images.txt -i rancher-images.tar.gz -r reg.czl.com/library #仓库地址包含具体的项目 rancher-load-images.sh 脚本下载地址：https://github.com/rancher/rancher/releases 选择需要版本，点击assets 展开后就有这个脚本下载 逐个导入镜像 cd $DIR/images_file for image_name in $(ls ./) do docker load "},"k8s/kubectl-user-instruction.html":{"url":"k8s/kubectl-user-instruction.html","title":"kubectl常用命令汇总（以及curl注入）","keywords":"","body":"kubectl 常用的命令总结 kubectl 详细命令用法可以参考官网： https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands 常用命令： 查看 只显示默认命名空间的pods kubectl get pods 显示所有空间的pod kubectl get pods --all-namespaces 显示指定空间的pod kubectl get pods -o wide --namespace apm 其中--namespace 与-n 作用等同，后面接命名空间参数 kubectl get deployment -n apm kubectl get pods,svc,rc -n apm svc和services是一样的 这些命令都可以通过 kubectl get --help 来查看帮助 删除 只能删除默认命名空间的deployment kubectl delete deployment nginx 删除指定空间的deployment/其他资源等 kubectl delete TYPE RESOURCE -n NAMESPACE 具体如下： kubectl delete deployment shop-app -n test-shop kubectl delete TYPE --all -n NAMESPACE kubectl delete all -n NAMESPACE kubectl delete all --all 使用yaml文件创建pod kubectl apply -f apptrace-receiver-deployment.yaml apply 和 create 命令都可以后跟yaml，创建所需资源,初次创建pod时可以互相替换使用；如果已有pod只是用于更新的话，又可以和replace相互替换使用；本着化繁就简的原则，create和replace都使用apply; 而且apply属于申明式语法，这个更加灵活，多次执行不会报错，只会更新改变的部分；像Jenkinsfile也已经从脚本语法向申明式转变。 使用kubectl命令把pod、卷、各种资源导出为yaml格式： kubectl get pods podA -n NAMEAPSCE-A -o yaml --export> padA.yaml pod 可以换成其他申明式资源如卷、services等；如果不带上--export 生成文件会有很多无用的内容 现在很多产品如rancher openshift，等；UI界面 直接可视化操作导出各种资源，掌握命令很多时候，可以事半功倍。-o更详细用法 下面有单独说明。 查看命名空间apm的collector服务详情 ```kubectl describe service/apptrace-collector --namespace apm --namespace 和-n 作用相同 - 查看pod日志 ```kubectl logs podname --namespace apm (可以带上 -f 参数) 为节点机apm-docker001打标签 zookeeper-node=apm-docker001,查看标签等； 为节点机打标签和查看 kubectl label nodes apm-docker001 zookeeper-node=apm-docker001 kubectl get nodes --show-labels 为命名空间打标签和查看 kubectl label namespace $your-namesapce istio-injection=enabled kubectl get namespaces --show-labels 给名为foo的Pod添加label unhealthy=true kubectl label pods foo unhealthy=true 查看某种类型字段下有哪些参数； kubectl explain pods kubectl explain Deployment kubectl explain Deployment.spec kubectl explain Deployment.spec.spec kubectl explain Deployment.spec.template kubectl explain Deployment.spec.template.spec 如查看Deployment.spec.template 可以有哪些参数 [root@k8s-master ~]# kubectl explain Deployment.spec.template KIND: Deployment VERSION: extensions/v1beta1 RESOURCE: template DESCRIPTION: Template describes the pods that will be created. PodTemplateSpec describes the data a pod should have when created from a template FIELDS: metadata Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#metadata spec Specification of the desired behavior of the pod. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status 在pod内部，执行shell命令 kubectl exec podname printenv | ps aux | cat、ls 某个文件（如果pod不在默认空间，用-n 指定相应空间） 如：kubectl exec app-demo-68b4bd9759-sfpcf -n test-shop printenv 或者在kubectl exec podname -- 再跟shell命令 如： kubectl exec -it spark-master-xksl -c spark-master -n spark -- mkdir -p /usr/local/spark shell命令前，要加-- 号，不然shell命令中的参数，不能识别 kubectl exec 后面只能是pod,目前还不支持deployment daemonnset等 巧用kubectl 帮助文件 如你只记得部分命令 get ,可以用 kubectl get --help 同理 kubectl create rolebinding 不知道后面接什么 也可以--help一下,记得关键字越多 带上后再使用help，如果只记得部分 就先help 如 kubectl create --help 这样create 所有类型的应用怎么创建 都有了 同样也可以直接 kubectl --help 这样kubectl 有哪些用法就显示出来， 我们要一级级的利用帮助 可能刚开始记住前面一个关键字，写完关键字 help一下 又有很多详细的用法 kubectl 命令规律总结 先看一组命令 kubectl delete sa metricbeat -n efk kubectl get sa --all-namespaces kubectl delete daemon-set metricbeat -n efk 1.会发现，kubectl 不管get 、delete describe等操作 后面跟资源类型 如果sa(serviceaccout) deployment pod,然后是资源名称，如果没有资源名称，则删除、获取此类型所有的资源；最后限定某个命名空间，或者全部命名空间；这个限定命名空间 可以放在kubectl 后面，也可以放在所有参数后面 -o 是指定输出格式 输出格式 说明 -o=custom-columns= 根据自定义列名进行输出，以逗号分隔 -o=custom-colimns-file= 从文件中获取自定义列名进行输出 -o=json 以JSON格式显示结果 -o=jsonpath= 输出jsonpath表达式定义的字段信息 -o=jsonpath-file= 输出jsonpath表达式定义的字段信息，来源于文件 -o=name 仅输出资源对象的名称 -o=wide 输出额外信息。对于Pod，将输出Pod所在的Node名 -o=yaml 以yaml格式显示结果 如下： kubectl get sa -n efk -o yaml kubectl get sa efk-elaticsearch -n efk -o yaml >xxx.yaml kubectl get pod efk-elaticsearch-0 -n efk -o wide 更多用法可以参照官网或者国内翻译的博客 https://blog.csdn.net/xingwangc2014/article/details/51204224 因为k8s 采用的是REST API接口，所有命令都最终会转换成curl -X PUT POS等形式,为什么不直接使用curl命令，因为需要一堆相关授权，rancher UI里面 在deploy或其他资源中，选择api查看 就可以查到，也可以点击右侧的edit编辑后 通过curl命令提交 API Request cURL command line: curl -u \"${CATTLE_ACCESS_KEY}:${CATTLE_SECRET_KEY}\" \\ -X PUT \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{\"annotations\":{\"cattle.io/timestamp\":\"\", \"cni.projectcalico.org/podIP\":\"10.42.1.44/32\"}, \"containers\":[{\"allowPrivilegeEscalation\":false, \"exitCode\":null, \"image\":\"172.16.35.31:1180/apm-images/gettoken:1.0\", \"imagePullPolicy\":\"IfNotPresent\", \"initContainer\":false, \"name\":\"genttoken\", \"ports\":[{\"containerPort\":8001, \"dnsName\":\"genttoken-nodeport\", \"kind\":\"NodePort\", \"name\":\"8001tcp301001\", \"protocol\":\"TCP\", \"sourcePort\":30100, \"type\":\"/v3/project/schemas/containerPort\"}], \"privileged\":false, \"procMount\":\"Default\", \"readOnly\":false, \"resources\":{\"type\":\"/v3/project/schemas/resourceRequirements\"}, \"restartCount\":0, \"runAsNonRoot\":false, \"state\":\"running\", \"stdin\":true, \"stdinOnce\":false, \"terminationMessagePath\":\"/dev/termination-log\", \"terminationMessagePolicy\":\" 等等 修改完成后 可以点击send request来提交 "},"k8s/docker-run-and-k8s-command.html":{"url":"k8s/docker-run-and-k8s-command.html","title":"docker run image -args对应yaml语法/rancher UI操作方式","keywords":"","body":"如何区分image与container中的entrypoint、cmd关系 不管是用kubernetes还是docker-compose来管理容器，其command参数相当于覆盖了镜像的entrypoint，args相当于覆盖了镜像的CMD；若采用编排工具管理容器，如果没有重新定义entrypoint和cmd，就默认使用镜像的entrypoint和cmd；如果容器编排工具中只使用了args参数，相当于image的entrypoint+编排工具定义args参数；如果容器中同时定义了 command和args ，容器入口就变成了command+args，image中定义的entrypoint和cmd会完全被覆盖掉。 如何对着docker run image -args,来填写容器编排配置（kubernetes、docker-compose)文件 kubectl 与 Docker 命令关系 可以参考：http://docs.kubernetes.org.cn/70.html 我们经常能在某个image官方文档中看到 像docker run image -args这种用法，这就行相当于改写了其entrypoint或cmd，那这些args若是在kubernetes或docker-compose的yaml中怎么配置呢，如：docker run -it xxx /bin/sh，相当于把入口变为/bin/sh; 还有像 redis 镜像官网说明: docker run redis --requirepass passwd 运行一个带密码的容器；若在k8s的yaml、rancherUI（甚至是docker-compose）里面怎么配置呢，最简单办法 是查看这个镜像的dockerfile中的entrypoint ：docker-entrypoint.sh(只展示了部分代码) if [ \"${1#-}\" != \"$1\" ] || [ \"${1%.conf}\" != \"$1\" ]; then set -- redis-server \"$@\" fi 从上面代码，可以看出如果参数不是“-”开头或者\".conf\"结尾，会自动变成redis-server + args（args为自定义的参数），若参数是“-”开头或“.conf”结尾，会直接用CMD命令+参数；所以在k8s（docker-compose)配置文件args里面可以直接跟参数，如果第一个参数写成了redis-server也没关系，镜像入口文件已做处理；也可以直接定义command，但必须以redis-server开头+参数；为何是redis-server开头呢，这个是从redis的镜像cmd中获得的。 如果你使用rancher，直接在 UI界面，点击编辑-更多就会显示命令(Command)输入框，有两个输入框，分别是entrypoint和command；entrypoint对应yaml配置是command，command对应的yaml配置是args； 像redis加密，可以直接在rancher UI界面的command填写:--requirepass \"自己的密码\" 或redis-server --requirepass \"自己的密码\" ，甚至可以再entrypoint里面填写：redis-server --requirepass \"自己的密码\" 都可以，但不能在entrypoint中填写：--requirepass \"自己的密码\"。完成后可以验证，密码是否生效； 有一种情况：如果没有找到镜像的dockerfile，当run镜像后，到容器中的默认的目录，查看是否有个可执行的二进制文件，然后在command 里面设置 “二进制文件 -args ”但这个需要验证； 注意如果在args里面应用环境变量，要写成$(VALUE),不能写成$VALUE,如引用hostname，要写成$(HOSTNAME)，这相当于填写的是此变量的value ，而不是value name； 实战： packetbeat 官网镜像 使用参考 docker run -d \\ --name=packetbeat \\ --user=packetbeat \\ --volume=\"/etc/localtime:/etc/localtime:ro\" \\ --cap-add=\"NET_RAW\" \\ --cap-add=\"NET_ADMIN\" \\ --network=host \\ docker.elastic.co/beats/packetbeat:7.1.1 \\ --strict.perms=false -e \\ -E setup.kibana.host=ip:port \\ -E output.elasticsearch.hosts=ip:port 镜像后面的参数转换成配置文件 args: [ \"--strict.perms=false\", \"-e\", \"-E\",\"setup.kibana.host=ip:port\", \"-E\",\"output.elasticsearch.hosts=ip:port\" ] 如果使用rancher 直接UI上编辑 即可修改 "},"jenkins/jenkins-slave-for-docker.html":{"url":"jenkins/jenkins-slave-for-docker.html","title":"Jenkins调用docker编译程序","keywords":"","body":"如果用docker 容器编译程序 有两种方案可供选择 1，激活镜像作为slave编译 采用Jenkins提供的jnlp-slave 或ssh-slave 标准镜像二次封装，或者初始镜像，然后通过label 选择镜像后进行编译； 这种编译的原理是：Jenkins通过标签选择相关docker镜像，并激活成容器，把此容器当做slave（节点机）使用； ​ Jenkins提供的镜像地址：https://hub.docker.com/u/jenkinsci ​ jnlp-slave 和ssh-slave 镜像都能激活作为slave节点使用，区别是采用不同协议连接到容器内部：ssh和jnlp； 使用这种方式需要额外在Jenkins里面配置，插件里面安装docker插件，然后配置Docker Host URL,来找到可以使用的docker，如果Jenkins和docker在同一台服务器可以直接填写为：unix:///var/run/docker.sock ，如果不在同一台机器要填写docker所在的机器ip：tcp://ip:2375，并且要在docker所在机器的 /etc/docker/daemon.json 里面添加2375端口 \"hosts\": [ ​ \"tcp://0.0.0.0:2375\", ​ \"unix:///var/run/docker.sock\" ​ ] 具体怎么调用这里不作为重点，这里重点说明的方案的选择，可以参考 https://blog.csdn.net/qq_31977125/article/details/82999872 这位博主有详细的操作步骤 下面是重点说明编译方式 2，直接docker run编译 把源码下载到宿主机，通过-v 挂载到容器中，然后指定入口命令编译此目录，编译完成后 销毁容器 docker run --rm -v `pwd`:/mypro -w /mypro nodeshift/centos7-s2i-nodejs:10.16.0 /bin/bash -c \"npm install\" docker run --rm -v `pwd`:/opt/mypro -w /opt/mypro goenv-centos:test7 /bin/bash -c \"GOPROXY=https://goproxy.io /usr/local/go/bin/go build\" 上面两个是例子，goenv-centos:test7是自制作的镜像 注意：提前制作好镜像，镜像里面把各种编译依赖放进去，制作镜像有两种方式 ​ 激活一个基础镜像，编译下载各种依赖库，能正式编译后，commit容器为镜像，这种方式不推荐 ​ 建议把操作步骤整理起来 编写到dockerfile中 实战案例 基于centos7.6 镜像制作出可以编译go/rust程序的镜像（生产中最好一个镜像只编译一种语言程序，并且是基于此语言的镜像） Dockerfile FROM centos:7.6.1810 WORKDIR /opt ADD https://github.com/facebook/zstd/releases/download/v1.4.0/zstd-1.4.0.tar.gz ./ ADD https://github.com/edenhill/librdkafka/archive/master.zip ./ ADD https://studygolang.com/dl/golang/go1.12.5.linux-amd64.tar.gz ./ COPY expect.sh ./ RUN mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.bak && \\ curl -s http://mirrors.aliyun.com/repo/Centos-7.repo -o /etc/yum.repos.d/CentOS-Base.repo && \\ curl -s http://mirrors.aliyun.com/repo/epel-7.repo -o /etc/yum.repos.d/epel-7.repo && \\ yum repolist && \\ yum -y install wget make expect gcc gcc-c++ unzip openssl-devel clang-devel libpcap-devel perl.x86_64 \\ which.x86_64 git && \\ curl -sSf https://sh.rustup.rs -o rustup.sh && chmod a+x rustup.sh && \\ chmod a+x expect.sh && /bin/bash ./expect.sh && \\ source $HOME/.cargo/env && \\ tar xzf zstd-1.4.0.tar.gz && \\ tar xzf go1.12.5.linux-amd64.tar.gz -C /usr/local && \\ unzip master.zip && \\ cd zstd-1.4.0 && CFLAGS=\"-O3 -fPIC\" make install && \\ cd ../librdkafka-master && ./configure --prefix=/usr && make && make install && \\ cp -rf /usr/lib/librdkafka* /usr/lib/pkgconfig /usr/lib64 && \\ chmod a+x -R /usr/local/go && \\ echo -e 'export GOPROXY=https://goproxy.io' >> /etc/profile && \\ echo -e 'export GOROOT=/usr/local/go' >> /etc/profile && \\ echo -e 'export GOPATH=/opt/mypro' >> /etc/profile && \\ echo -e 'export export PATH=$GOROOT/bin:/root/.cargo/bin:$PATH' >> /etc/profile && \\ echo -e 'export LIBRARY_PATH=$LIBRARY_PATH:/usr/lib64/llvm' >> /etc/profile && \\ echo -e 'export LD_LIBRARY_PATH=/usr/local/lib/:${LD_LIBRARY_PATH}' >> /etc/profile && \\ source /etc/profile && \\ yum clean all && \\ rm -rf /opt/* && \\ mkdir -p /opt/mypro COPY ustc-config /root/.cargo/config ustc-config [source.crates-io] registry = \"https://github.com/rust-lang/crates.io-index\" replace-with = 'ustc' [source.ustc] registry = \"git://mirrors.ustc.edu.cn/crates.io-index\" expect.sh #!/usr/bash expect 把Dockerfile，和expect.sh、ustc-config放在同一目录，然后在此目录执行build命令： docker build -t 172.16.35.31:1180/apm-images/centos7-goenv:1:1 . go程序编译： docker run --rm -v `pwd`:/opt/mypro -w /opt/mypro 172.16.35.31:1180/apm-images/centos7-goenv:1 /bin/bash -c \"GOPROXY=https://goproxy.io /usr/local/go/bin/go build\" rust程序编译 docker run --rm -v `pwd`:/opt/mypro -w /opt/mypro 172.16.35.31:1180/apm-images/centos7-goenv:1 /bin/bash -c \"/root/.cargo/bin/cargo build --release\" 这种方式编译最大优点，不管是开发、运维还是测试都无需搭建编译环境（有时候搭建一套编译环境是费时费力的事情，而且移植性差），直接从docker仓库拉取此镜像后就能编译； "},"jenkins/install-jenkins.html":{"url":"jenkins/install-jenkins.html","title":"利用docker 镜像，快速搭建Jenkins环境","keywords":"","body":"利用docker image快速搭建Jenkins环境 关于安装部署Jenkins，网上一大堆资料，这里不做详细说明了；可以下载Jenkins的war包直接放到tomcat（其他Java容器也行）通过ip:8080/jenkins即可访问，也可能通过 java –jar Jenkins.war来安装或者带上--ajp13Port=-1 --httpPort=8081参数指定端口就行； 这里重点说的是采用docker化部署，这种方案更快捷和灵活： docker run \\ --name myjenkins \\ --cpus=4 \\ --restart=unless-stopped \\ -u root \\ -d \\ -p 88:8080 \\ -p 50002:50000 \\ -v /home/jenkinsci/jenkins:/var/jenkins_home \\ -v /opt/jenkins-bak-file:/opt/jenkins-bak-file \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /etc/localtime:/etc/localtime:ro \\ -v /etc/timezone:/etc/timezone:ro \\ -v $HOME/.ssh:/root/.ssh:ro \\ jenkinsci/blueocean /etc/timezone 如果没有可以创建一个:echo Asia/Shanghai >/etc/timezone 这个 一定要设置，要不然就是GMT时区了； /opt/jenkins-bak-file目录是为以后Jenkins自身备份预留的目录； 把.ssh挂载进去，让容器使用宿主机的私钥； 如果使用jenkins:2.60.3镜像的话，宿主机的/home/Jenkins 目录一定要sudo chown -R 1000 处理一下；但不推荐这种镜像，已经不支持blueocean了； "},"shell/get_dir_in_shell.html":{"url":"shell/get_dir_in_shell.html","title":"shell 脚本中获取脚本所在路径","keywords":"","body":"shell脚本中获取路径两种方法 第一种 DIR=$(cd $(dirname $0) && pwd ) echo $DIR 第二种 DIR2=$(cd $(dirname \"${BASH_SOURCE[0]}\") && pwd ) echo $DIR2 上面两种方法都可以获取到当前路径，但第二种方法只适用于含有bash命令的系统，若系统只有sh命令，建议采用第一种方式 "},"shell/sed_use_hard.html":{"url":"shell/sed_use_hard.html","title":"sed不常见用法","keywords":"","body":"1 sed -i '/ADMIN URL/s/localhost/172.17.0.1/; /DATA URL/s/localhost/172.17.0.1/; s/localhost:8082/172.17.0.1:8082/; N;/16379/s/localhost/172.17.0.1/;P;D;' $CONFIG_DIR/fusion_config/production.js sed 可以一次性执行多行代码，每行代码用分号隔开；上面代码块，前两行表示定位后进行替换操作，第三行代码匹配后就替换；第四行代码是模式空间指针到16379后（模式空间有两行），把模式空间里面的localhost替换掉。大写PD 表示打印模式空间第一行和删除第一行； 2 sed -i '/^\\s$/d' test.txt 删除空白行 sed -i 's/\\s//' test.txt 表示删除每行开头的空格 sed -i 's/\\s//g' test.txt 表示删除每行所有的空格 sed -i 's/\\s//;s/\\s$//g' test.txt 删除行首和行尾的空格 也可以拆开写 把删除行尾的空格单独为：sed -i 's/\\s$//g' 正则表达式\\s表示任意空白字符 不管是tab 还是空格 sed 模式匹配的g参数： g是起到一个全局的作用，这个范围是每一行，也就是说是一行为单位，作为一个全局。+g :匹配每一行有行首到行尾的所有字符 所以慎用参数g 3 指定行修改，如第4行末尾追加一行，内容为test sed -i 'N;4atest' test.txt 第4行行首追加一行，内容为test sed -i 'N;4itest' test.txt "},"jmeter/use_jmeter_test_app.html":{"url":"jmeter/use_jmeter_test_app.html","title":"利用jmeter模拟手机接口测试","keywords":"","body":"利用jmeter模拟手机接口测试 本文示例是从网上找到的月光茶人APP程序 首先手机操作月光茶人app一个完整的购买支付流程 我们在监听平台中查看其产生的url（接口），下列列表为手机操作支付流程时，监听平台采集到数据 现实测试的APP，我们可以通过开发提供的api文档、抓包工具如fiddler，抓取app的访问请求，都可以获取到接口URL；如何获取具体接口需要灵活应变；通过浏览器访问的程序可以直接通过Chrome调试network就能获取到接口URL. 上面列表是手机操作月光茶人APP：登录、首页列表、产品列表、加入购物车、成功加入到购物车、加入预购订单、预购订单详情、选择支付、订单提交成功产生的URL接口； 这9步构成一个完整的流程；我们把这9步的http请求加入到jmeter里面 通过监控平台采集到URL进行分析，发现其他步骤会用到登录后产生的返回体里面appCartCookieId和appLoginToken动态参数，所以我们要在登录请求后面加入正则表达式提取器 来提取，它返回的参数 .\"appCartCookieId\":\"(.+?)\". 这个正则表达式 要提取appCartCookieId：后面\"\"里面包含的内容 $1$表示 当有多个正则表达式时，只获取第一个，匹配数字1，表示从第一个开始；匹配数字，-1表示取出所有匹配值 0是随机，1 、2 表示匹配第几个 ​ 如果有多个值和appCartCookieId匹配，一定要用$1$这种形式来选择值，若有极端情况，有多个匹配值且位置不定 如：“address\":{\"area\":{\"store_id\":\"1\",\"shippingGroup\":\"\",\"pathNames\":\"中国/广东省/深圳市/宝安区/福永/福围-下沙南\",\"name\":\"福围-下沙南\",\"id\":\"1000000\",\"pathNames4Print\":\"深圳市宝安区福永福围-下沙南\"},\"isDefault\":\"1\",\"telephone\":\"18812341234\",\"id\":\"100347013e14430696ec765ff464429c\" 取\"18812341234后面的id，可以写成\"18812341234\"\\,\"id\":\"(.+?)\".* ​ 如果手机号是变动的，可以写成\"1[3|4|5|8][0-9]\\d{4,8}\"\\,\"id\":\"(.+?)\".* 手机号正则表达式不能写成：^1[3|4|5|8][0-9]\\d{4,8}$，^和$表示行开始和结束，要去掉，这里手机号并不是独占一行。 接下的步骤就可以引用这两个参数，如下图可以写成parameters里面引用参数，也可以直接在body data里面编写多个参数，多个参数用&来连接 如果想在路径里面使用上一个请求产生的参数，body data或者parameters必须带上这个参数，哪怕请求body体用不上这个参数 最后添加用于查看结果的“查看结果树”和“聚合报告”，在“查看结果树”里面可以详细看到响应的数据、请求数据、取样结果等信息 聚合报告汇总了接口访问总量错误信息等关键指标 也可以把抓包获取的header添加到jmeter里面（模拟的更真实一些，表头一般是存储设备等信息的） 这样发送过来的请求,监控平台上设备就显示为iphone了 模拟登录月光茶人APP后选购支付流程大量并发的实现 如果APP对登录有限制，同一账号只能同时登录一次，且手里没有多余的账号如何进行并发测试呢，这个时候只需单独对登录http请求进行控制即可；其他请求操作可以放在一块进行并发测试； 新建一个setUp Thread Group ​ 使用这个进程组的好处时，他可以和tearDown Thread Group一起使用，构成一个 登录+中间各种操作/请求+退出的流程（单独使用setUp、tearDown也可以），登录请求放在setUp Thread Group,退出请求放在tearDown Thread Group里面，剩下的各种操作http请求放在线程组里面，我们此处没有用到退出操作就不需要新建tearDown Thread Group线程组了； 如下图，在setUp Thread Group里面添加登录http请求后，我们需要获取appCartCookieId和 appLoginToken参数并且要全局化，下面其他进程中的http请求能继续使用；首先用正则表达式提取器提取相关参数，具体操作步骤前面有说过，不再赘述 “(.+?)”.* , (.+?)表示惰性匹配，表示从“开始，然后匹配到” 然后存起来；用\\1 \\2 或者$1 $2 取出第一个 第二个字符； 使用全局变量 添加后置处理器BeanShell PostProcessor，把上一步正则表达式提取器提取参数全局化；如下图 parameters参数填写正则表达式提取器提取的参数，然后在script模块进行全局化申明： String appCartCookieId = bsh.args[0]; ​ print (appCartCookieId); ​ ${__setProperty(newappCartCookieId,${appCartCookieId},)} 引用全局化参数 在其他进程组里面，进行引用全局化参数，引用格式：${__P(newappCartCookieId,)} 上图除了全局变量外，还引用了其他参数： _terminal-type=ios&appCartCookieId=${P(newappCartCookieId,)}&appLoginToken=${P(newappLoginToken,)}&userId=e19fd14f3ebf48bcbc79d09d6775ff04；也可以写成parameters的形式，详细讲解可以参考：http://www.cnblogs.com/allen-zml/p/6552535.html 可以在登录线程组里面添加http信息头管理，填写设备信息tid、uid等这样模拟出来的请求更接近iOS移动设备发出的请求； 控制吞吐量 确定要添加控制吞吐量的位置后，添加-定时器-Constant Throughput Timer，然后填写如图相关信息 如果想控制每秒2个并发，红色区域1填写120即可，如果Constant Throughput Timer添加到所有线程组的前面，都要用到此控制器，下拉选择all active threads选项；如果放到某一进程组，只供此进程组使用，可以选择this thread only； "},"ca/make_key.html":{"url":"ca/make_key.html","title":"私有证书制作","keywords":"","body":"制作自签名证书 1，手动制作自签名证书（NGINX用） openssl req -newkey rsa:2048 -nodes -keyout tls.key -x509 -days 3650 -out tls.pem -subj /C=CN/ST=BJ/L=CY/O=DCLINGCLOUD/OU=APM/CN=apptrace/emailAddress=ca@dclingcloud.cc 注：-keyout 和 -out 可以修改为输出路径+文件名称，名称可以自定义 字段说明： C=CN // 国家代号，中国输入CN ST=BJ // 州（省）名 L=CY // 所在地市的名称 O=DCLINGCLOUD // 组织或者公司名称 OU=APM // 部门名称 CN=apptrace // 通用名，可以是服务器域控名称，或者个人的名字 emailAddress=ca@dclingcloud.cc // 管理邮箱名 2，利用脚本制作所需证书（可以用在harbor和kubernetes、rancher部署上） 脚本下载地址（rancher中国提供） https://github.com/xiaoluhong/server-chart/blob/v2.2.4/create_self-signed-cert.sh 脚本使用示例 cat /etc/hosts 192.16.1.100 Centos76 reg.czl.com 具体名称和设置的自签名域名一致 ./create_self-signed-cert.sh --ssl-domain=reg.czl.com --ssl-trusted-ip=192.16.1.100 详细的用法可以参考脚本下载链接 "},"git/git-use.html":{"url":"git/git-use.html","title":"git日常使用命令","keywords":"","body":"git常见用法 正常提交流程 1，首先从GitHub/gitlab服务器拉下来 git clone 仓库地址 如果使用ssh协议，还需要生成公私钥对，把公钥存储到仓库中 2，然后编辑和添加文件后 git add . （所有文件） git add filename(具体某个文件） 3，然后提交 git commit -m \"message更新信息\" 若没有新增文件，只修改文件，上面两步可以合并为 git commit -am \"message\" 4，最后上传 git push [-u origin your_branch] 把某个分支的文件copy到其他分支，如A分支文件copy到B分支 1,首先切换到B分支 git checkout branchB 2,在B分支下执行 git checkout branchA（A分支） file1 file2 … 3，剩下的步骤是提交和推送，和上面一样； 合并分支 把A分支所有的提交合并到B 首先同步A分支，使A分支本地和远程仓库保持一致 切换到B分支后 git checkout B git merge A 然后A分支的内容就merge到B上了 如果有冲突，通过 git status 查看一下冲突文件，解决冲突，git add 冲突文件后， 剩下的提交和推送操作参照上面步骤 把A 分支某（几）次提交也提交到 B分支 在 A分支下执行 git log 查找到相关提交记录 切换到B分支，git checkout B 把A的某次提交，也提交到B： git cherry-pick 7f00fe9ebb（提交号） 把A的某几次提交，也提交到B： git cherry-pick 7f00fe9ebb..7f00fe9ebb（提交范围） 如果有冲突，通过 git status 查看一下冲突文件，解决冲突，git add 冲突文件后，剩下的提交和推送操作参照上面步骤 没有冲突直接执行 git push [-u origin your_branch] 针对某次提交 打tag 1，使用git log查看提交日志，找出你需要的那个commit。假设提交的commit id git checkout 使用git tag进行打标签，例如：git tag -a v1.4 -m ‘xxxx’ git push origin --tags或者git push origin [tagname] git checkout -b newbranch git push origin newbranch git fetch 与 git pull git fetch origin master:tmp 在本地新建一个temp分支，并将远程origin仓库的master分支代码下载到本地temp分支 git push origin tmp 把tmp分支推送到远程仓库 git pull 相当于 git fetch + git merge 如 git pull tmp相当于 git fetch origin/tmp + git merge origin/tmp 把远程tmp merge到本地tmp分支中 本地仓库回退到某个版本　　 git　　reset　　–hard　　bae168 创建空白新分支 git branch git checkout git rm --cached -r . git clean -f -d 创建空的commit git commit --allow-empty -m \"[empty] initial commit\" 推送新分支 git push origin 把修改存到缓存中 git stash git stash pop(这个会把缓存拿出来，删除缓存） 或 git stash git stash list(查看stash列表） git stash apply [列表名称] .gitignore 的设置： 很多时候，有些文件不需要提交，如开发人员本地环境配置，就用到了.gitignore 只忽略dbg目录，不忽略dbg文件 dbg/ 只忽略dbg文件，不忽略dbg目录 dbg !dbg/ 若把某些目录或文件加入忽略规则，按照上述方法定义后发现并未生效，原因是.gitignore只能忽略那些原来没有被追踪的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未被追踪状态），然后再提交，这样就不会出现忽略的文件了。git清除本地缓存命令如下： git rm -r --cached . git add . git commit -m 'message' 最后说一个 强制推送（操作前要慎之又慎） git push -f [-u origin your_branch] 这些功能 基本能覆盖到git日常90%使用，剩下的，可以网上搜索资料，或者在git bash 中使用帮助，如 git commit --help; "}}